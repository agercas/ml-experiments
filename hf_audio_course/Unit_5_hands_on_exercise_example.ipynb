{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9858,
     "status": "ok",
     "timestamp": 1688910207567,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "xjUYWoBkmVEY"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio transformers transformers[torch] datasets[audio] evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1688910209088,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "NMZonIc9m26P"
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "referenced_widgets": [
      "d14cdf27a6d54f44830afb91ba8cbfb5",
      "bbe7c59fa2b648528a74164231462117",
      "313dc010aea7413fac6be0e82f6295ab",
      "f65aec370651440e989f61fdef57b830",
      "27c1c7529d0946e99a602e75fb7360de",
      "f2aa8a3263da432888620d6d17ad3cda",
      "9bd3064d317847e6a6a43ec76dbdce58",
      "370bfb5605384adf88684b2aec25b9ff",
      "e7ba1753e5864a28a9b0a365b8da85fa",
      "67f383706a4c4098b2a91db6104256cf",
      "83a331c21feb4044aca2250803688a9d",
      "763560e347b14a7497fe05ebe4db533d",
      "a5d4ddba494047bc8491b7da89fe0f1d",
      "e39f3c7953d14f4caa5fe27aa4e5fa49",
      "e940522e0f494bdbbeedff18f9a609b9",
      "7b2e04ffa4134ab88dd2b41d20ccc05b",
      "f43347575aac43a98148680adfb0c8c5"
     ]
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688910209089,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "R0LhOmEEm3fO",
    "outputId": "452cb8d2-e3c3-471b-bfb9-395e4092ebc5"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2757,
     "status": "ok",
     "timestamp": 1688910211842,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "23Gg4w9-m3oj",
    "outputId": "d231b919-21fd-42c1-dc94-afbe6949d3b5"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"train+validation\")\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"test\")\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1641,
     "status": "ok",
     "timestamp": 1688910213481,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "OkUfbLXAm306",
    "outputId": "f81a7035-da46-4720-d589-356b45e34bad"
   },
   "outputs": [],
   "source": [
    "from transformers.models.whisper.tokenization_whisper import TO_LANGUAGE_CODE\n",
    "\n",
    "TO_LANGUAGE_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1688910214203,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "slV6zMHds_LY"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"sinhalese\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688910214203,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "8QzXxtGKtbYk",
    "outputId": "b223ea26-65b5-4e00-ef4e-63f360ef9ed7"
   },
   "outputs": [],
   "source": [
    "common_voice[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688910214204,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "ptz2ndfttkJB"
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688910214204,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "46KYm1MhtkbL"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example = processor(\n",
    "        audio=audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        text=example[\"sentence\"],\n",
    "    )\n",
    "\n",
    "    # compute input length of audio sample in seconds\n",
    "    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4826,
     "status": "ok",
     "timestamp": 1688910219027,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "auxmKLEztki1",
    "outputId": "ffbd8be2-1d55-418a-e998-9be2bc5c64a1"
   },
   "outputs": [],
   "source": [
    "common_voice = common_voice.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=common_voice.column_names[\"train\"],\n",
    "    num_proc=1,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688910219027,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "lcL6sj3ptkpu"
   },
   "outputs": [],
   "source": [
    "max_input_length = 30.0\n",
    "\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length < max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688910219027,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "m8JTcC3AtkwY",
    "outputId": "481f3e5f-40d2-4ba0-b1ca-8d738017d186"
   },
   "outputs": [],
   "source": [
    "common_voice[\"train\"] = common_voice[\"train\"].filter(\n",
    "    is_audio_in_length_range,\n",
    "    input_columns=[\"input_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688910219027,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "sMl-rEW7tlHi",
    "outputId": "21c07d8f-056d-4eb0-99a8-12717ce5f86c"
   },
   "outputs": [],
   "source": [
    "common_voice[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3561,
     "status": "ok",
     "timestamp": 1688910222579,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "LpHCe9kJuKCz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"][0]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1688910222580,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "6oSq6rcauKYA"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9157,
     "status": "ok",
     "timestamp": 1688910231719,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "al1K4eQyuKh5"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1688910231720,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "n1orufSZuzpZ"
   },
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # compute orthographic wer\n",
    "    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # compute normalised WER\n",
    "    pred_str_norm = [normalizer(pred) for pred in pred_str]\n",
    "    label_str_norm = [normalizer(label) for label in label_str]\n",
    "    # filtering step to only evaluate the samples that correspond to non-zero references:\n",
    "    pred_str_norm = [pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0]\n",
    "    label_str_norm = [label_str_norm[i] for i in range(len(label_str_norm)) if len(label_str_norm[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)\n",
    "\n",
    "    return {\"wer_ortho\": wer_ortho, \"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6588,
     "status": "ok",
     "timestamp": 1688910238289,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "Irqu93E_uzuT"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1688910238289,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "g0Mpxm16uzzQ"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-dv\",  # name on the HF Hub\n",
    "    per_device_train_batch_size=8,  # reduce by a factor of 2 if hit a out-of-memory error\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_steps=50,\n",
    "    max_steps=500,  # increase to 4000 if you have your own GPU or a Colab paid plan\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4888,
     "status": "ok",
     "timestamp": 1688910243156,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "4mbNk6GOuKoS",
    "outputId": "fb264b5d-b949-4f0d-9d2e-16b0ec46e1b4"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "executionInfo": {
     "elapsed": 3252299,
     "status": "ok",
     "timestamp": 1688913495430,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "xZ3s5PUDwJto",
    "outputId": "b554a156-ee1a-4799-b3d7-649f7a90ce17"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1688913495430,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "GCPUxhWVwKW-"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"mozilla-foundation/common_voice_13_0\",\n",
    "    \"dataset\": \"Common Voice 13\",  # a 'pretty' name for the training dataset\n",
    "    \"language\": \"dv\",\n",
    "    \"model_name\": \"Whisper Small Dv - Sanchit Gandhi\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377,
     "referenced_widgets": [
      "fd13f8bf7f7347efb63295f56e55b631",
      "3c2a480306a54471a22f9b817afcd9c0",
      "515509a97522416f805a1fe2598bc8dc",
      "ab59523b2e954736afe18d7c12ef3caf",
      "883dbddc1cfd474cbed45eea7c55bf45",
      "1094199a44b847d4ae9620bd661fc152",
      "358cfb11c4174566b2bff8df1188f1b5",
      "5076dc345bf244dcbd0e4a7757e778a1",
      "dc48f422668b4a7f97ab46c0a4605a28",
      "94edccda616f4cc39798690b3bda33a3",
      "724f780e0e5a419eacd0615cf8becb64",
      "a9ab71cc674d4183bdaf4d5740374357",
      "55e5f02c852c4b019486a438e0dc8f36",
      "e12adf538acf4367ba7e10505884867d",
      "5a76ca58ced24e188f6a706c7eab8711",
      "b38bb441068244d6a01af22ebba8eecd",
      "b1ea176b09b24cc987834668b71b4f51",
      "419b1a39c86e49b0b325f621a9552fc9",
      "afe0119bfd70401bb1827ae174e5fb48",
      "b806598330484638a3813e3502dd30a0",
      "8b33d50704ed4bb28946dd76eaadece2",
      "879b03527be64a2891a10da6c1279a5e"
     ]
    },
    "executionInfo": {
     "elapsed": 45042,
     "status": "ok",
     "timestamp": 1688913540466,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "LlKLL3ZewKno",
    "outputId": "73ad4fb7-3161-457c-848b-a5628954f88b"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1688913540467,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "S6aR6-XYuKv5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM/NyAFYKcbX5Swcimgen5o",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
