{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12449,
     "status": "ok",
     "timestamp": 1688916839236,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "xjUYWoBkmVEY"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio transformers transformers[torch] datasets[audio] evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2192,
     "status": "ok",
     "timestamp": 1688916841424,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "NMZonIc9m26P"
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "referenced_widgets": [
      "41d7221b6c4146d2b34e5ac92a89fda2",
      "f1289abd0eb543299b7160f9f223be79",
      "462975a8b7d943f5be2dff8f62e8be6c",
      "43200cb1347c4adcac1cae95280bc653",
      "e10a677b4b034da288678b7417616876",
      "5d7c924ffc3b43dfaea1742ba306bad7",
      "12d5984019244c65946f5de7080237db",
      "00ba672eadb5402395e8a1e7c96a1d06",
      "e9a580ad5ee1442f9d246321dca461cd",
      "a73a4e4237ad41a0b4bfe885bf0cd6ca",
      "47aa702c66ee4e87a7d9999bb190b598",
      "6fbe8c53855f42bd9e6578e38d8619a1",
      "614e98b20df24e38a47c69f42405c194",
      "0cb00ae38ffe4e068ada046805832b8f",
      "9a6c9bf47535403ca7bb6e35a12d6f2e",
      "5acc86768d6448b6a2b2eaccc446a1f6",
      "fd83f6abdc3747339a79a19cef5b6235"
     ]
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688916841424,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "R0LhOmEEm3fO",
    "outputId": "528215bc-3fc2-435c-bc77-9601bb3f6e77"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1349,
     "status": "ok",
     "timestamp": 1688916842765,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "23Gg4w9-m3oj",
    "outputId": "3614f75d-9b8b-4133-ce73-9a70185f4ba8"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
    "columns_to_remove = [\"lang_id\", \"english_transcription\", \"intent_class\"]\n",
    "minds = minds.remove_columns(columns_to_remove)\n",
    "\n",
    "minds = minds.rename_column(\"transcription\", \"sentence\")\n",
    "\n",
    "# common_voice = DatasetDict()\n",
    "\n",
    "# common_voice[\"train\"] = load_dataset(\n",
    "#     \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"train+validation\"\n",
    "# )\n",
    "# common_voice[\"test\"] = load_dataset(\n",
    "#     \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"test\"\n",
    "# )\n",
    "\n",
    "# print(common_voice)\n",
    "\n",
    "\n",
    "data = minds.train_test_split(seed=42, shuffle=False, train_size=450)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1688916844754,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "slV6zMHds_LY"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688916844754,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "8QzXxtGKtbYk",
    "outputId": "c291636a-eb3e-4759-ca74-19213d731b65"
   },
   "outputs": [],
   "source": [
    "data[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688916844754,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "ptz2ndfttkJB"
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "sampling_rate = processor.feature_extractor.sampling_rate\n",
    "data = data.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688916844755,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "46KYm1MhtkbL"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    example = processor(\n",
    "        audio=audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        text=example[\"sentence\"],\n",
    "    )\n",
    "\n",
    "    # compute input length of audio sample in seconds\n",
    "    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54,
     "referenced_widgets": [
      "3e9762e7dc11456fb068f9ac68302d74",
      "a0dfc8fc670f41f3a87c8c62901e32ae",
      "e343a9ef8bcb40459a6aeb6f50a1e244",
      "7e47cab74c38424f92f248aa48ac46c3",
      "17120ea9656f4c5aafa73954859f63e9",
      "4b1ca755a98f4dea955de907b13bb17a",
      "c6e46fcf80604c18894d6c70382ae167",
      "baa2f93242354b8c9ad2772e5fee0580",
      "bbbda6f5bc3d4a21b1139fc52698720d",
      "ac8291c6bb344274acd18ca8df521780",
      "230afa268dc7400d9cc7586cfbe25aa4"
     ]
    },
    "executionInfo": {
     "elapsed": 34941,
     "status": "ok",
     "timestamp": 1688916879690,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "auxmKLEztki1",
    "outputId": "317ae876-6b34-478e-c3a7-88013781c429"
   },
   "outputs": [],
   "source": [
    "data = data.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=data.column_names[\"train\"],\n",
    "    num_proc=1,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1688916879690,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "lcL6sj3ptkpu"
   },
   "outputs": [],
   "source": [
    "max_input_length = 30.0\n",
    "\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length < max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1688916879691,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "m8JTcC3AtkwY",
    "outputId": "92da5f30-d49c-4012-e891-21f43364f16e"
   },
   "outputs": [],
   "source": [
    "data[\"train\"] = data[\"train\"].filter(\n",
    "    is_audio_in_length_range,\n",
    "    input_columns=[\"input_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688916879691,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "sMl-rEW7tlHi",
    "outputId": "407a7789-498c-4469-eea8-f1a1cb8eb5ee"
   },
   "outputs": [],
   "source": [
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688916879691,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "LpHCe9kJuKCz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"][0]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688916879691,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "6oSq6rcauKYA"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1835,
     "status": "ok",
     "timestamp": 1688916881515,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "al1K4eQyuKh5"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688916881515,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "n1orufSZuzpZ"
   },
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # compute orthographic wer\n",
    "    wer_ortho = metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    # compute normalised WER\n",
    "    pred_str_norm = [normalizer(pred) for pred in pred_str]\n",
    "    label_str_norm = [normalizer(label) for label in label_str]\n",
    "    # filtering step to only evaluate the samples that correspond to non-zero references:\n",
    "    pred_str_norm = [pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0]\n",
    "    label_str_norm = [label_str_norm[i] for i in range(len(label_str_norm)) if len(label_str_norm[i]) > 0]\n",
    "\n",
    "    wer = metric.compute(predictions=pred_str_norm, references=label_str_norm)\n",
    "\n",
    "    return {\"wer_ortho\": wer_ortho, \"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1688916882424,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "Irqu93E_uzuT"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688916882425,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "g0Mpxm16uzzQ"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-tiny-us\",  # name on the HF Hub\n",
    "    per_device_train_batch_size=16,  # reduce by a factor of 2 if hit a out-of-memory error\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"constant_with_warmup\",\n",
    "    warmup_steps=50,\n",
    "    max_steps=500,  # increase to 4000 if you have your own GPU or a Colab paid plan\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2478,
     "status": "ok",
     "timestamp": 1688916884895,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "4mbNk6GOuKoS",
    "outputId": "b72940f1-7802-4cf0-c035-ec7b5773eb08"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "executionInfo": {
     "elapsed": 1403574,
     "status": "ok",
     "timestamp": 1688918288456,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "xZ3s5PUDwJto",
    "outputId": "cb1e5ae0-ed2d-4564-a639-321ca2d63063"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688918288456,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "GCPUxhWVwKW-"
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"PolyAI/minds14\",\n",
    "    \"finetuned_from\": \"openai/whisper-tiny\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437,
     "referenced_widgets": [
      "702af04c47ff4e189a21c46513bf9f3c",
      "0f1676d44b3c4a14af162ad0c6144c50",
      "fc3291bcc4b14352a2c5c73938da621b",
      "f8528afdae104b959471f843c10a3fff",
      "5a50df075a1e49cbb4d558c975071a35",
      "ec8ae2ed4c4840deb6464fad6f9c71d8",
      "66f6b7b341de4a3b841d4cfcab544dea",
      "3fa5fd56a0b64354a81c21f70a9e6441",
      "d960424c82f846c09eda206749f01cd4",
      "feb78119dc354ce7aba8da089e12d955",
      "cd7559f01d11462f8ac5c800f1e43059",
      "c2b8373f8c5f4dd1a6984b52ebaa36ba",
      "1ea549ff47d94bbf836a11af65ddba09",
      "8f40fa6940074a3f897cb36db0982fa5",
      "a4eeb077a2584a39aff72791eee7e0be",
      "d25abb9088bf4965a20c6e9d0deaba5a",
      "3b6f1ff2706945bbb03f7789742e3922",
      "731d099c401e495cbe42642167ac0a2b",
      "8840ede863fd459897bb9cb2f13c89a0",
      "96bef542992d40d495e28214ca2482bb",
      "e66ca5d76c6d428c890b033783d42ff9",
      "ad2c47fc76824c9cbf16bfb8219085ae",
      "99fb8a514dc3488191963f1200cc9982",
      "a828e62af8224af8842fae5f991be5a0",
      "5a259285cbe445a6b6d07f40eda7bda5",
      "20e3eb31794b4097bb169904443dd75b",
      "a3640bcd34a1409a82171e7b0589d130",
      "beaea79f3b2c4b6a830548042a1c29f9",
      "bbbb4b362ddc495ca1d26e5bbd34dded",
      "6f456f55e27e45748f4419109b849604",
      "43838bdad03a4bf699b08c75f77946c8",
      "9ca046a08e504a57bdbb8084687263fb",
      "e3d4ddf3a46941c28d8a7c5a044ce0f5"
     ]
    },
    "executionInfo": {
     "elapsed": 20859,
     "status": "ok",
     "timestamp": 1688918309313,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "LlKLL3ZewKno",
    "outputId": "f4c248d1-608d-4e81-f5ce-eed63bbc8961"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1688918309314,
     "user": {
      "displayName": "Arnas Gercas",
      "userId": "05721695559367193707"
     },
     "user_tz": -120
    },
    "id": "S6aR6-XYuKv5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmlcAnDN4F2GlhyxrJFCyb",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
